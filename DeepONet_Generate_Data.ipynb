{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b50386-47b4-45fb-b1fe-17e9f59a8f76",
   "metadata": {},
   "source": [
    "## Install all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d50d4a-dcd6-454d-b3af-9f8d192b2bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jax\n",
    "!pip install tqdm\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96827156-2f5f-4261-8dac-bcf1329e367f",
   "metadata": {},
   "source": [
    "## Import All Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d87afec-5c3a-4e86-8e04-cbe12972f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8:wq\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "#DeepONet JAX code solving Posson equation with spatial source term as its parameter\n",
    "#Developed by Seid Koric, NCSA, University of Illinois, from the 1D code by Wang et. al DOI: 10.1126/sciadv.abi8605\n",
    "#Explicit iterative jacobi scheme used for data generation \n",
    "\n",
    "\n",
    "from __future__ import print_function    \n",
    "import jax\n",
    "import jax.numpy as np\n",
    "from jax import random, grad, vmap, jit, hessian, lax\n",
    "#from jax.experimental import optimizers\n",
    "from jax.example_libraries import optimizers\n",
    "from jax.nn import relu\n",
    "##from jax.ops import index_update, index\n",
    "from jax.flatten_util import ravel_pytree\n",
    "\n",
    "import itertools\n",
    "from functools import partial\n",
    "from torch.utils import data\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import time\n",
    "import math\n",
    "import numpy as onp\n",
    "import pylab as py\n",
    "#import scipy.sparse as sp                 # import sparse matrix library\n",
    "#from jax.scipy.sparse.linalg import spsolve\n",
    "#from jax.scipy.sparse.linalg import bicgstab\n",
    "#import scipy.fftpack\n",
    "\n",
    "#from scipy.interpolate import RectBivariateSpline\n",
    "\n",
    "from matplotlib import pyplot, cm\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e914a9-5119-4c89-9f19-24f4f3d4599e",
   "metadata": {},
   "source": [
    "## Create Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e410a3bb-ff47-4e46-84eb-ae967d5a5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "py.rcParams.update({'font.size': 20})\n",
    "\n",
    "# import the file where the differentiation matrix operators are defined\n",
    "#from diff_matrices import Diff_mat_1D, Diff_mat_2D   \n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Data generator\n",
    "class DataGenerator(data.Dataset):\n",
    "    def __init__(self, u, u_map, y, s,  \n",
    "                 batch_size=64, rng_key=random.PRNGKey(1234)):\n",
    "        'Initialization'\n",
    "        self.u = u # input sample with NO repeats\n",
    "        self.u_map = u_map # Repeat map\n",
    "        self.y = y # location\n",
    "        self.s = s # labeled data evulated at y (solution measurements, BC/IC conditions, etc.)\n",
    "        \n",
    "        self.N = u_map.shape[0]\n",
    "        self.batch_size = batch_size\n",
    "        self.key = rng_key\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        self.key, subkey = random.split(self.key)\n",
    "        inputs, outputs = self.__data_generation(subkey)\n",
    "        return inputs, outputs\n",
    "\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def __data_generation(self, key):\n",
    "        'Generates data containing batch_size samples'\n",
    "        idx = random.choice(key, self.N, (self.batch_size,), replace=False)\n",
    "        s = self.s[idx,:]\n",
    "        y = self.y[idx,:]\n",
    "        u = self.u[ self.u_map[idx] ,:]\n",
    "        # Construct batch\n",
    "        inputs = (u, y)\n",
    "        outputs = s\n",
    "        return inputs, outputs\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Define the neural net\n",
    "def MLP(layers, activation=relu):\n",
    "  ''' Vanilla MLP'''\n",
    "  def init(rng_key):\n",
    "      def init_layer(key, d_in, d_out):\n",
    "          k1, k2 = random.split(key)\n",
    "          glorot_stddev = 1. / np.sqrt((d_in + d_out) / 2.)\n",
    "          W = glorot_stddev * random.normal(k1, (d_in, d_out))\n",
    "          b = np.zeros(d_out)\n",
    "          return W, b\n",
    "      key, *keys = random.split(rng_key, len(layers))\n",
    "      params = list(map(init_layer, keys, layers[:-1], layers[1:]))\n",
    "      return params\n",
    "  def apply(params, inputs):\n",
    "      for W, b in params[:-1]:\n",
    "          outputs = np.dot(inputs, W) + b\n",
    "          inputs = activation(outputs)\n",
    "      W, b = params[-1]\n",
    "      outputs = np.dot(inputs, W) + b\n",
    "      return outputs\n",
    "  return init, apply\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Define the model\n",
    "class DeepONet:\n",
    "    def __init__(self, branch_layers, trunk_layers):    \n",
    "        # Network initialization and evaluation functions\n",
    "        self.branch_init, self.branch_apply = MLP(branch_layers, activation=np.tanh)  # or Relu \n",
    "        self.trunk_init, self.trunk_apply = MLP(trunk_layers, activation=np.tanh)     # or Relu\n",
    "\n",
    "        # Initialize\n",
    "        branch_params = self.branch_init(rng_key = random.PRNGKey(1234))\n",
    "        trunk_params = self.trunk_init(rng_key = random.PRNGKey(4321))\n",
    "        params = (branch_params, trunk_params)\n",
    "\n",
    "        # Use optimizers to set optimizer initialization and update functions\n",
    "        self.opt_init, \\\n",
    "        self.opt_update, \\\n",
    "        self.get_params = optimizers.adam(optimizers.exponential_decay(1e-3, \n",
    "                                                                      decay_steps=2000, \n",
    "                                                                      decay_rate=0.9))\n",
    "        self.opt_state = self.opt_init(params)\n",
    "\n",
    "        # Used to restore the trained model parameters\n",
    "        _, self.unravel_params = ravel_pytree(params)\n",
    "\n",
    "        self.itercount = itertools.count()\n",
    "\n",
    "        # Loggers\n",
    "        self.loss_log = []\n",
    "\n",
    "    # Define DeepONet architecture\n",
    "    def operator_net(self, params, u, x, t):\n",
    "        branch_params, trunk_params = params\n",
    "        y = np.stack([x, t])\n",
    "        B = self.branch_apply(branch_params, u)\n",
    "        T = self.trunk_apply(trunk_params, y)\n",
    "        outputs = np.sum(B * T)\n",
    "        return  outputs\n",
    "  \n",
    "    # Define operator loss\n",
    "    def loss_operator(self, params, batch):\n",
    "        inputs, outputs = batch\n",
    "        u, y = inputs\n",
    "        # Compute forward pass\n",
    "        s_pred = vmap(self.operator_net, (None, 0, 0, 0))(params, u, y[:,0], y[:,1])\n",
    "        # Compute loss\n",
    "        loss = np.mean((outputs.flatten() - s_pred.flatten())**2)\n",
    "        return loss\n",
    "\n",
    "    # Define a compiled update step\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def step(self, i, opt_state, batch):\n",
    "        params = self.get_params(opt_state)\n",
    "        g = grad(self.loss_operator)(params, batch)\n",
    "        return self.opt_update(i, g, opt_state)\n",
    "\n",
    "    # Optimize parameters in a loop\n",
    "    def train(self, dataset, nIter = 10000):\n",
    "        # Define data iterators\n",
    "        data_iterator = iter(dataset)\n",
    "\n",
    "        pbar = trange(nIter)\n",
    "        # Main training loop\n",
    "        for it in pbar:\n",
    "            # Fetch data\n",
    "            batch = next(data_iterator)\n",
    "           \n",
    "            self.opt_state = self.step(next(self.itercount), self.opt_state, batch)\n",
    "            \n",
    "            if it % 100 == 0:\n",
    "                params = self.get_params(self.opt_state)\n",
    "\n",
    "                # Compute loss\n",
    "                loss_value = self.loss_operator(params, batch)\n",
    "\n",
    "                # Store loss\n",
    "                self.loss_log.append(loss_value)\n",
    "  \n",
    "                # Print loss\n",
    "                pbar.set_postfix({'Loss': loss_value})\n",
    "           \n",
    "    # Evaluates predictions at test points  \n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def predict_s(self, params, U_star, Y_star):\n",
    "        s_pred = vmap(self.operator_net, (None, 0, 0, 0))(params, U_star, Y_star[:,0], Y_star[:,1])\n",
    "        return s_pred\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Defining custom plotting functions\n",
    "def my_contourf(x,y,F,ttl):\n",
    "    cnt = py.contourf(x,y,F,12,cmap = 'jet')\n",
    "    py.colorbar()\n",
    "    py.xlabel('x'); py.ylabel('y'); py.title(ttl)\n",
    "    return 0\n",
    "    \n",
    "\n",
    "def RBF(x1, x2, params):\n",
    "    output_scale, lengthscales = params\n",
    "    diffs = np.expand_dims(x1 / lengthscales, 1) - \\\n",
    "            np.expand_dims(x2 / lengthscales, 0)\n",
    "    print (\"diffs.shape = \", diffs.shape)\n",
    "    r2 = np.sum(diffs**2, axis=2)\n",
    "    return output_scale * np.exp(-0.5 * r2)\n",
    "\n",
    "#RBF source function \n",
    "def func(x, y, length_scale):\n",
    "    #Generate a GP sample\n",
    "    #length_scale = 0.1\n",
    "    N = len(x)\n",
    "#    print(\"N = \",N)\n",
    "    gp_params = (1.0, length_scale)\n",
    "    jitter = 1e-10\n",
    "#    print(\"x.shape = \", x.shape)\n",
    "#    print(\"y.shape = \", y.shape)\n",
    "    K = RBF(x, y, gp_params)\n",
    "#    print(\"K.shape = \", K.shape)\n",
    "    L = np.linalg.cholesky(K + jitter*np.eye(N))\n",
    "    value = np.dot(L, np.random.normal(size=[N,N]))\n",
    "    return value \n",
    "\n",
    "def my_fftshift(x, axes=None):\n",
    "    \"\"\"\n",
    "    Shift the zero-frequency component to the center of the spectrum.\n",
    "    This function swaps half-spaces for all axes listed (defaults to all).\n",
    "    Note that ``y[0]`` is the Nyquist component only if ``len(x)`` is even.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array_like\n",
    "        Input array.\n",
    "    axes : int or shape tuple, optional\n",
    "        Axes over which to shift.  Default is None, which shifts all axes.\n",
    "    Returns\n",
    "    -------\n",
    "    y : ndarray\n",
    "        The shifted array.\n",
    "    See Also\n",
    "    --------\n",
    "    ifftshift : The inverse of `fftshift`.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> freqs = np.fft.fftfreq(10, 0.1)\n",
    "    >>> freqs\n",
    "    array([ 0.,  1.,  2., ..., -3., -2., -1.])\n",
    "    >>> np.fft.fftshift(freqs)\n",
    "    array([-5., -4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.])\n",
    "    Shift the zero-frequency component only along the second axis:\n",
    "    >>> freqs = np.fft.fftfreq(9, d=1./9).reshape(3, 3)\n",
    "    >>> freqs\n",
    "    array([[ 0.,  1.,  2.],\n",
    "           [ 3.,  4., -4.],\n",
    "           [-3., -2., -1.]])\n",
    "    >>> np.fft.fftshift(freqs, axes=(1,))\n",
    "    array([[ 2.,  0.,  1.],\n",
    "           [-4.,  3.,  4.],\n",
    "           [-1., -3., -2.]])\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    if axes is None:\n",
    "        axes = tuple(range(x.ndim))\n",
    "        shift = [dim // 2 for dim in x.shape]\n",
    "    elif isinstance(axes, integer_types):\n",
    "        shift = x.shape[axes] // 2\n",
    "    else:\n",
    "        shift = [x.shape[ax] // 2 for ax in axes]\n",
    "\n",
    "    return np.roll(x, shift, axes)\n",
    "\n",
    "def fftind(size):\n",
    "    \"\"\" Returns a numpy array of shifted Fourier coordinates k_x k_y.\n",
    "        \n",
    "        Input args:\n",
    "            size (integer): The size of the coordinate array to create\n",
    "        Returns:\n",
    "            k_ind, numpy array of shape (2, size, size) with:\n",
    "                k_ind[0,:,:]:  k_x components\n",
    "                k_ind[1,:,:]:  k_y components\n",
    "                \n",
    "        Example:\n",
    "        \n",
    "            print(fftind(5))\n",
    "            \n",
    "            [[[ 0  1 -3 -2 -1]\n",
    "            [ 0  1 -3 -2 -1]\n",
    "            [ 0  1 -3 -2 -1]\n",
    "            [ 0  1 -3 -2 -1]\n",
    "            [ 0  1 -3 -2 -1]]\n",
    "            [[ 0  0  0  0  0]\n",
    "            [ 1  1  1  1  1]\n",
    "            [-3 -3 -3 -3 -3]\n",
    "            [-2 -2 -2 -2 -2]\n",
    "            [-1 -1 -1 -1 -1]]]\n",
    "            \n",
    "        \"\"\"\n",
    "    k_ind = np.mgrid[:size, :size] - int( (size + 1)/2 )\n",
    "    k_ind = my_fftshift(k_ind)\n",
    "    return( k_ind )\n",
    "\n",
    "\n",
    "def gaussian_random_field(key, alpha = 3.0,\n",
    "                          size = 128, \n",
    "                          flag_normalize = True):\n",
    "    \n",
    "    subkeys = random.split(key[0], num=2)\n",
    "    \"\"\" Returns a numpy array of shifted Fourier coordinates k_x k_y.\n",
    "        \n",
    "        Input args:\n",
    "            alpha (double, default = 3.0): \n",
    "                The power of the power-law momentum distribution\n",
    "            size (integer, default = 128):\n",
    "                The size of the square output Gaussian Random Fields\n",
    "            flag_normalize (boolean, default = True):\n",
    "                Normalizes the Gaussian Field:\n",
    "                    - to have an average of 0.0\n",
    "                    - to have a standard deviation of 1.0\n",
    "        Returns:\n",
    "            gfield (numpy array of shape (size, size)):\n",
    "                The random gaussian random field\n",
    "                \n",
    "        Example:\n",
    "        import matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "        example = gaussian_random_field()\n",
    "        plt.imshow(example)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Defines momentum indices\n",
    "    k_idx = fftind(size)\n",
    "\n",
    "        # Defines the amplitude as a power law 1/|k|^(alpha/2)\n",
    "    amplitude = np.power( k_idx[0]**2 + k_idx[1]**2 + 1e-10, -alpha/4.0 )\n",
    "    #amplitude[0,0] = 0\n",
    "    amplitude = amplitude.at[0,0].set(0)\n",
    "    \n",
    "        # Draws a complex gaussian random noise with normal\n",
    "        # (circular) distribution\n",
    "    noise = random.normal(subkeys[1], (size, size)) \\\n",
    "        + 1j * random.normal(subkeys[1], (size, size))\n",
    "    \n",
    "    #random.normal(subkeys[0], (size,size))\n",
    "        # To real space\n",
    "    gfield = np.fft.ifft2(noise * amplitude).real\n",
    "    \n",
    "        # Sets the standard deviation to one\n",
    "    if flag_normalize:\n",
    "        gfield = gfield - np.mean(gfield)\n",
    "        gfield = gfield/np.std(gfield)\n",
    "        \n",
    "    return gfield\n",
    "\n",
    "\n",
    "def interp2d(\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    xp: np.ndarray,\n",
    "    yp: np.ndarray,\n",
    "    zp: np.ndarray,\n",
    "    fill_value: np.ndarray = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Bilinear interpolation on a grid.\n",
    "    Args:\n",
    "        x, y: 1D arrays of point at which to interpolate. Any out-of-bounds\n",
    "            coordinates will be clamped to lie in-bounds.\n",
    "        xp, yp: 1D arrays of points specifying grid points where function values\n",
    "            are provided.\n",
    "        zp: 2D array of function values. For a function `f(x, y)` this must\n",
    "            satisfy `zp[i, j] = f(xp[i], yp[j])`\n",
    "    Returns:\n",
    "        1D array `z` satisfying `z[i] = f(x[i], y[i])`.\n",
    "    \"\"\"\n",
    "    if xp.ndim != 1 or yp.ndim != 1:\n",
    "        raise ValueError(\"xp and yp must be 1D arrays\")\n",
    "    if zp.shape != (xp.shape + yp.shape):\n",
    "        raise ValueError(\"zp must be a 2D array with shape xp.shape + yp.shape\")\n",
    "\n",
    "    ix = np.clip(np.searchsorted(xp, x, side=\"right\"), 1, len(xp) - 1)\n",
    "    iy = np.clip(np.searchsorted(yp, y, side=\"right\"), 1, len(yp) - 1)\n",
    "\n",
    "    # Using Wikipedia's notation (https://en.wikipedia.org/wiki/Bilinear_interpolation)\n",
    "    z_11 = zp[ix - 1, iy - 1]\n",
    "    z_21 = zp[ix, iy - 1]\n",
    "    z_12 = zp[ix - 1, iy]\n",
    "    z_22 = zp[ix, iy]\n",
    "\n",
    "    z_xy1 = (xp[ix] - x) / (xp[ix] - xp[ix - 1]) * z_11 + (x - xp[ix - 1]) / (\n",
    "        xp[ix] - xp[ix - 1]\n",
    "    ) * z_21\n",
    "    z_xy2 = (xp[ix] - x) / (xp[ix] - xp[ix - 1]) * z_12 + (x - xp[ix - 1]) / (\n",
    "        xp[ix] - xp[ix - 1]\n",
    "    ) * z_22\n",
    "\n",
    "    z = (yp[iy] - y) / (yp[iy] - yp[iy - 1]) * z_xy1 + (y - yp[iy - 1]) / (\n",
    "        yp[iy] - yp[iy - 1]\n",
    "    ) * z_xy2\n",
    "\n",
    "    if fill_value is not None:\n",
    "        oob = (x < xp[0]) | (x > xp[-1]) | (y < yp[0]) | (y > yp[-1])\n",
    "        z = np.where(oob, fill_value, z)\n",
    "\n",
    "    return z\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#analytical quadratic source function \n",
    "def func_org(x,y):\n",
    "    #value = (-4 * x**2  + 4*x) * (-4 * y**2 + 4*y)\n",
    "    value = (-4 * (x-0.25)**2  + 4*(x-0.25) * (-4 * (y-0.25)**2 + 4*(y-0.25)))\n",
    "    return value\n",
    "\n",
    "#https://scipython.com/book/chapter-8-scipy/examples/two-dimensional-interpolation-with-scipyinterpolaterectbivariatespline/\n",
    "def f_fn_f(xp, yp, zp, xc, yc):\n",
    "    xp = onp.array(xp)\n",
    "    yp = onp.array(yp)\n",
    "    zp = onp.array(zp)\n",
    "    xc = onp.array(xc)\n",
    "    yc = onp.array(yc)  \n",
    "    \n",
    "    f_fn = RectBivariateSpline(xp[:,None], yp[:,None], zp)\n",
    "    z_test_tmp = f_fn(xc,yc)\n",
    "    return z_test_tmp\n",
    "\n",
    "def plot2D(x, y, p):\n",
    "    fig = pyplot.figure(figsize=(11, 7), dpi=100)\n",
    "    ax = fig.gca(projection='3d')\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    surf = ax.plot_surface(X, Y, p[:], rstride=1, cstride=1, cmap=cm.viridis,\n",
    "            linewidth=0, antialiased=False)\n",
    "    ax.view_init(30, 225)\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$y$')\n",
    "    ax.set_zlabel('$u$')\n",
    "    pyplot.show()\n",
    "    \n",
    "@jax.jit   \n",
    "def explicit_update(pd,dx,dy,z_test):\n",
    "    # Initialization\n",
    "    k = 0.01\n",
    "#    print(\"Nx = \", Nx)\n",
    "    UU_loc  = np.zeros((Ny, Nx))\n",
    "#    pd = np.zeros((Ny, Nx))\n",
    "\n",
    "    UU_loc = UU_loc.at[1:-1,1:-1].set(((pd[1:-1, 2:] + pd[1:-1, :-2]) * dy**2 +\n",
    "                    (pd[2:, 1:-1] + pd[:-2, 1:-1]) * dx**2 +\n",
    "                    z_test[1:-1, 1:-1]/k * dx**2 * dy**2) / \n",
    "                    (2 * (dx**2 + dy**2)))\n",
    "\n",
    "#y is first indices in BC \n",
    "    UU_loc = UU_loc.at[0, :].set(0)\n",
    "    UU_loc = UU_loc.at[Ny-1, :].set(0)\n",
    "    UU_loc = UU_loc.at[:, 0].set(0)\n",
    "    UU_loc = UU_loc.at[:, Nx-1].set(0)\n",
    "        \n",
    "    return(UU_loc)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# A diffusion-reaction numerical solver\n",
    "# A diffusion-reaction numerical solver\n",
    "def solve_ADR(key, Nx, Ny, P):\n",
    "    # Generate subkeys\n",
    "    subkeys = random.split(key, 2)\n",
    "\n",
    "    x = np.linspace(0,1,Nx)        # x variables in 1D\n",
    "    y = np.linspace(0,1,Ny)        # y variable in 1D\n",
    "\n",
    "    # Initialization\n",
    "    UU  = np.zeros((Ny, Nx))\n",
    "    pd = np.zeros((Ny, Nx))\n",
    "    \n",
    "    \n",
    "    dx = x[1] - x[0]                # grid spacing along x direction\n",
    "    dy = y[1] - y[0]                # grid spacing along y direction\n",
    "\n",
    "    X,Y = np.meshgrid(x,y)          # 2D meshgrid\n",
    "\n",
    "# 1D indexing\n",
    "    Xu = X.ravel()                  # Unravel 2D meshgrid to 1D array\n",
    "    Yu = Y.ravel()\n",
    "\n",
    "\n",
    "#None adds an axis to numpy array, x[:,None] has (100,1) dimnesion, single column\n",
    "#y[None,:] has (1,100) dimnesion, i.e a single row \n",
    "\n",
    "    #bf = func_org(x[:,None], y[None,:])\n",
    "    bf = gaussian_random_field(subkeys, 3, Nx)\n",
    "    \n",
    "    print(\"type of bf \", type(bf))\n",
    "    \n",
    "    #interpolate source function data \n",
    "#    start_time = time.time()\n",
    "    #z_test = f_fn_f(x, y, bf, x, y)\n",
    "    X_ij, Y_ij = np.meshgrid(x,y,indexing=\"ij\")\n",
    "    Xu_ij = X_ij.ravel()\n",
    "    Yu_ij = Y_ij.ravel()\n",
    "    u = interp2d(Xu_ij, Yu_ij, x, y, bf)\n",
    "#    print(\"x.shape = \", x.shape)\n",
    "#    print(\"y.shape = \", y.shape)\n",
    "    #print(\"z_test.shape = \", z_test.shape)\n",
    "#    print(\"2D Interpolation time = %1.6s\" % (time.time()-start_time))\n",
    "    #print(type(z_test))\n",
    "    z_test = u.reshape(Nx,Ny)\n",
    "#    plot2D(x, y, z_test)\n",
    "#    py.figure(figsize = (14,7))\n",
    "#    my_contourf(x,y,z_test,r'u distribution')\n",
    "    \n",
    "    \n",
    "#    start_time = time.time()\n",
    "    nt = 30000\n",
    "    for it in range(nt):\n",
    "        UU = explicit_update(pd,dx,dy,z_test)\n",
    "        pd = UU\n",
    "    \n",
    "#    print(\"Solver time = %1.6s\" % (time.time()-start_time))\n",
    "    \n",
    "\n",
    "#m defined outside is number of input sensors where u is evaluated \n",
    "#   m_x must be sqrt(m)\n",
    "#    m_x = 10\n",
    "    m_x = np.sqrt(m)\n",
    "    m_x = np.array(m_x.astype(np.int32))\n",
    "    \n",
    "    xx = np.linspace(0, 1, m_x)\n",
    "    yy = np.linspace(0, 1, m_x)\n",
    "#    u = f_fn_f(x, y, bf, xx, yy).ravel()\n",
    "    XX_ij, YY_ij = np.meshgrid(xx,yy,indexing=\"ij\")\n",
    "    XXu_ij = XX_ij.ravel()\n",
    "    YYu_ij = YY_ij.ravel()\n",
    "    u = interp2d(XXu_ij, YYu_ij, x, y, bf)\n",
    "\n",
    "#P is number of locations for evalution of s\n",
    "#P = Nx\n",
    "    #idx = np.random.randint(0, max(Nx, Ny),(P, 2))\n",
    "    idx = random.randint(subkeys[1], (P, 2), 0, max(Nx, Ny))\n",
    "    y_s = np.concatenate([x[idx[:,0]][:,None], y[idx[:,1]][:,None]], axis = 1)\n",
    "    s = UU[idx[:,0], idx[:,1]]\n",
    "\n",
    "    #print(\"u.shape = \", u.shape)\n",
    "    #print(\"y_s.shape = \", y_s.shape)\n",
    "    #print(\"s.shape = \", s.shape)\n",
    "    \n",
    "    return (x, y, UU, z_test), (u, y_s, s)\n",
    "\n",
    "# Geneate training data corresponding to one input sample\n",
    "def generate_one_training_data(key, P):\n",
    "    # Numerical solution\n",
    "#    print(\"Nx in generate_one_training_data = \", Nx)\n",
    "    (x, t, UU, z_test), (u, y, s) = solve_ADR(key, Nx , Nt, P)\n",
    "\n",
    "    # u = np.tile(u, (P, 1))\n",
    "\n",
    "    return u, y, s\n",
    "\n",
    "# Geneate test data corresponding to one input sample\n",
    "def generate_one_test_data(key, P):\n",
    "    Nx = P\n",
    "    Nt = P\n",
    "    (x, t, UU, z_test), (u, y, s) = solve_ADR(key, Nx , Nt, P,)\n",
    "\n",
    "    XX, TT = np.meshgrid(x, t)\n",
    "\n",
    "    #u_test = np.tile(u, (P**2, 1))\n",
    "    u_test = u\n",
    "    y_test = np.hstack([XX.flatten()[:,None], TT.flatten()[:,None]])\n",
    "    s_test = UU.T.flatten()\n",
    "    #s_test = UU.flatten()\n",
    "\n",
    "    return u_test, y_test, s_test, z_test\n",
    "\n",
    "\n",
    "# Geneate training data corresponding to N input sample\n",
    "def generate_training_data(key, N, P):\n",
    "    jax.config.update(\"jax_enable_x64\", True)\n",
    "    keys = random.split(key, N)\n",
    "    u_train, y_train, s_train= vmap(generate_one_training_data, (0, None))(keys, P)\n",
    "\n",
    "    # u_train = np.float32(u_train.reshape(N * P, -1))\n",
    "    u_train = np.float32(u_train.reshape(N, -1))\n",
    "    y_train = np.float32(y_train.reshape(N * P, -1))\n",
    "    s_train = np.float32(s_train.reshape(N * P, -1))\n",
    "\n",
    "    jax.config.update(\"jax_enable_x64\", False)\n",
    "    return u_train, y_train, s_train\n",
    "\n",
    "# Geneate test data corresponding to N input sample\n",
    "def generate_test_data(key, N, P):\n",
    "\n",
    "    jax.config.update(\"jax_enable_x64\", True)\n",
    "    keys = random.split(key, N)\n",
    "   \n",
    "    u_test, y_test, s_test, z_test = vmap(generate_one_test_data, (0, None))(keys, P)\n",
    "\n",
    "    #u_test = np.float32(u_test.reshape(N * P**2, -1))\n",
    "    #y_test = np.float32(y_test.reshape(N * P**2, -1))\n",
    "    #s_test = np.float32(s_test.reshape(N * P**2, -1))\n",
    "    \n",
    "    z_test = np.float32(z_test)\n",
    "\n",
    "    config.update(\"jax_enable_x64\", False)\n",
    "    return u_test, y_test, s_test, z_test\n",
    "\n",
    "# Compute relative l2 error over N test samples.\n",
    "def compute_error(key, P):\n",
    "    # Generate one test sample\n",
    "    u_test, y_test, s_test, z_test = generate_test_data(key, 1, P)\n",
    "    # Predict  \n",
    "    s_pred = model.predict_s(params, u_test, y_test)[:,None]\n",
    "    # Compute relative l2 error\n",
    "    error_s = np.linalg.norm(s_test - s_pred) / np.linalg.norm(s_test) \n",
    "    return error_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a448590a-7fed-42ca-bfcc-818a2e017d89",
   "metadata": {},
   "source": [
    "## Generate Data\n",
    "\n",
    "Creates the grid points that will get used to train the DeepONet using the generate_one_test_data function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799a5e50-1189-45e2-a159-15b7f3eb68e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(0)\n",
    "\n",
    "###generating data on all grid points for DeepXDE, no random choosing of P points \n",
    "### m is alos on all grid points, i.e. m = Nx x Ny\n",
    "\n",
    "# Resolution of the solution\n",
    "Nx = 128\n",
    "Nt = 128\n",
    "Ny = 128\n",
    "\n",
    "N = 5500 # number of input samples\n",
    "m = Nx * Ny   # number of input sensors for each u sample \n",
    "\n",
    "##(x, t, UU, z_test), (u, y, s) = solve_ADR(key, Nx , Ny, P_train)\n",
    "\n",
    "u_test, y_test, s_test, z_test =  generate_one_test_data(key, Nx)\n",
    "\n",
    "xy_train_test_ht = y_test\n",
    "print(\"xy_train_test_ht.shape = \", xy_train_test_ht.shape)\n",
    "np.save('xy_train_test_ht.npy', xy_train_test_ht)\n",
    "\n",
    "u_test, y_test, s_test, z_test = generate_test_data(key, N, Nx)\n",
    "\n",
    "\n",
    "#### debug for figure ####\n",
    "\"\"\"\n",
    "u_test, y_test, s_test, z_test = generate_test_data(key, 2, Nx)\n",
    "\n",
    "print(\"z_test.shape = \", z_test.shape)\n",
    "print(\"z_test[0].shape = \", z_test[0].shape)\n",
    "print(\"z_test[1].shape = \", z_test[1].shape)\n",
    "#print(\"z_test[0] = \", z_test[0])\n",
    "#print(\"z_test[1] = \", z_test[1])\n",
    "\n",
    "#z_test =z_test.reshape(z_test.shape[0],z_test.shape[1]*z_test.shape[2])\n",
    "#print(\"z_test.shape = \", z_test.shape)\n",
    "#print(\"z_test[0].shape = \", z_test[0].shape)\n",
    "#print(\"z_test[1].shape = \", z_test[1].shape)\n",
    "#print(\"z_test[0] = \", z_test[0])\n",
    "#print(\"z_test[1] = \", z_test[1])\n",
    "\n",
    "print(\"u_test.shape = \", u_test.shape)\n",
    "u_test_0 = u_test[0] \n",
    "print(\"u_test_0.shape = \", u_test_0.shape)\n",
    "#print(\"u_test[0] = \", u_test[0])\n",
    "#print(\"u_test[1] = \", u_test[1])\n",
    "\n",
    "z_test_0 = z_test[0]\n",
    "z_test_1 = z_test[1]\n",
    "\n",
    "print(\"z_test_0.shape = \", z_test_0.shape)\n",
    "print(\"z_test_1.shape = \", z_test_1.shape)\n",
    "\n",
    "s_test_0 = s_test[0]\n",
    "print(\"s_test_0.shape = \", s_test_0.shape)\n",
    "\n",
    "s_test_0_nx_ny = s_test_0.reshape(Nx,Ny)\n",
    "print(\"s_test_0_nx_ny.shape = \", s_test_0_nx_ny.shape)\n",
    "\n",
    "u_test_0_nx_ny = u_test_0.reshape(Nx,Ny)\n",
    "print(\"u_test_0_nx_ny.shape + \", u_test_0_nx_ny.shape)\n",
    "\n",
    "u_test_1_nx_ny = u_test[1].reshape(Nx,Ny)\n",
    "s_test_1_nx_ny = s_test[1].reshape(Nx,Ny)\n",
    "\n",
    "x = np.linspace(0, 1, Nx)\n",
    "y = np.linspace(0, 1, Ny)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(18,5))\n",
    "plt.subplot(1,2,1)\n",
    "#py.figure(figsize = (14,7))\n",
    "#my_contourf(x,y,z_test_0.T,r'Source Distrubution')\n",
    "my_contourf(x,y,u_test_1_nx_ny.T,r'Source Distrubution')\n",
    "plt.tight_layout()\n",
    "plt.subplot(1,2,2)\n",
    "#py.figure(figsize = (14,7))\n",
    "my_contourf(x,y,s_test_1_nx_ny,r'Reference Solution')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature_sample1_u.jpg\", dpi=300)\n",
    "#plt.show()\n",
    "\n",
    "\"\"\"\n",
    "##print(\"y_test.shape = \", y_test.shape)\n",
    "#print(\"s_test.shape = \", s_test.shape)\n",
    "\n",
    "#with np.printoptions(threshold=np.inf):\n",
    "#    print(\"s_test[0] = \", s_test[0])\n",
    "#    print(\"s_test[1] = \", s_test[1])\n",
    "#print(\"z_test.shape = \", z_test.shape)\n",
    "\n",
    "data_s_train_ht, data_s_testing_ht = np.split(s_test, [5000], axis=0)\n",
    "print(\"data_s_train_ht.shape = \", data_s_train_ht.shape)\n",
    "print(\"data_s_testing_ht.shape = \", data_s_testing_ht.shape)\n",
    "np.save(\"data_s_train_ht_3.npy\", data_s_train_ht)\n",
    "np.save(\"data_s_testing_ht_3.npy\", data_s_testing_ht)\n",
    "\n",
    "\n",
    "data_u0_train_ht, data_u0_testing_ht = np.split(u_test, [5000], axis=0)\n",
    "print(\"data_u0_train_ht.shape = \", data_u0_train_ht.shape)\n",
    "print(\"data_u0_testing_ht.shape = \", data_u0_testing_ht.shape)\n",
    "np.save(\"data_u0_train_ht_3.npy\", data_u0_train_ht)\n",
    "np.save(\"data_u0_testing_ht_3.npy\", data_u0_testing_ht)\n",
    "\n",
    "\n",
    "#This version just generates data for DeepXDE DeepONet, it can still train with Jax if below is uncommented \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Plot solution\n",
    "#py.figure(figsize = (14,7))\n",
    "#my_contourf(x,t,UU,r'$\\nabla^2 s + b$ = 0')\n",
    "\n",
    "#u_train1, y_train1, s_train1 = generate_one_training_data(key, P_train)\n",
    "#at P (128 output) locations, evaluete u_train with m (100 points) \n",
    "#print(\"u_train1.shape = \", u_train1.shape)\n",
    "#print(\"y_train1.shape = \", y_train1.shape)\n",
    "#print(\"s_train1.shape = \", s_train1.shape)\n",
    "\n",
    "\n",
    "#print(\"u_train1 = \", u_train1)\n",
    "#print(\"s_train1 = \", s_train1)\n",
    "\n",
    "#N(5000) u samples, each at P output locations(128) , evaluate each u_train with m (100 points)\n",
    "\n",
    "P_train = 800 # number of output locations (sensors)\n",
    "\n",
    "u_train, y_train, s_train = generate_training_data(key, N, P_train)\n",
    "u_map_train = np.repeat( np.arange(N) , P_train )\n",
    "print(\"u_train.shape = \", u_train.shape)\n",
    "print(\"u_map_train.shape = \", u_map_train.shape)\n",
    "print(\"y_train.shape = \", y_train.shape)\n",
    "print(\"s_train.shape = \", s_train.shape)\n",
    "\n",
    "np.save('u_train_N5000_P400_M144', u_train, allow_pickle=True)\n",
    "np.save('u_map_train_N5000_P400_M144', u_map_train, allow_pickle=True)\n",
    "np.save('y_train_N5000_P400_M144', y_train, allow_pickle=True)\n",
    "np.save('s_train_N5000_P400_M144', s_train, allow_pickle=True)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "#branch_layers = [m, 50, 50, 50, 50, 50]\n",
    "branch_layers = [m, 100, 100, 100, 100, 100, 100]\n",
    "#trunk_layers =  [2, 50, 50, 50, 50, 50]\n",
    "trunk_layers =  [2, 100, 100, 100, 100, 100, 100]\n",
    "model = DeepONet(branch_layers, trunk_layers)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Create data set\n",
    "batch_size = 10000\n",
    "dataset = DataGenerator(u_train, u_map_train , y_train, s_train, batch_size)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "start_time = time.process_time()\n",
    "# Train\n",
    "model.train(dataset, nIter=200000)\n",
    "print(\"Training time = %6.2f\" % (time.process_time()-start_time))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Test data\n",
    "N_test = 100 # number of input samples \n",
    "P_test = m # m number of input sensors for each u \n",
    "             # P number of output sensors\n",
    "key_test = random.PRNGKey(1234567)\n",
    "keys_test = random.split(key_test, N_test)\n",
    "\n",
    "# Predict\n",
    "params = model.get_params(model.opt_state)\n",
    "\n",
    "# Compute error\n",
    "error_s = vmap(compute_error, (0, None))(keys_test,P_test) \n",
    "\n",
    "print('mean of relative L2 error of s: {:.2e}'.format(error_s.mean()))\n",
    "print('std of relative L2 error of s: {:.2e}'.format(error_s.std()))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#Plot for loss function\n",
    "#import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (6,5))\n",
    "plt.plot(model.loss_log, lw=2)\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Generate one test sample\n",
    "#from scipy.interpolate import griddata\n",
    "for i in range(1):\n",
    "    key = random.PRNGKey(4511236)\n",
    "    P_test = m\n",
    "    Nx = m\n",
    "    u_test, y_test, s_test, z_test = generate_test_data(key, 1, P_test)\n",
    "#u_test, y_test, s_test = generate_one_test_data(key,P_test)\n",
    "\n",
    "# Predict\n",
    "    params = model.get_params(model.opt_state)\n",
    "#params_tmp = onp.asarray(params)\n",
    "\n",
    "    start_time = time.time()\n",
    "    s_pred = model.predict_s(params, u_test, y_test)\n",
    "    s_pred_tmp = onp.asarray(s_pred)\n",
    "    print(\"Inference time = %1.6s\" % (time.time()-start_time))\n",
    "\n",
    "# Generate an uniform mesh\n",
    "    x = np.linspace(0, 1, Nx)\n",
    "    t = np.linspace(0, 1, Nt)\n",
    "    XX, TT = np.meshgrid(x, t)\n",
    "\n",
    "# Grid data\n",
    "    S_pred = griddata(y_test, s_pred.flatten(), (XX,TT), method='cubic')\n",
    "    S_test = griddata(y_test, s_test.flatten(), (XX,TT), method='cubic')\n",
    "\n",
    "# Compute the relative l2 error \n",
    "    error = np.linalg.norm(S_pred - S_test, 2) / np.linalg.norm(S_test, 2) \n",
    "    print('Relative l2 errpr: {:.3e}'.format(error))\n",
    "    z_test = np.squeeze(z_test, axis=0)\n",
    "#z_test = np.float32(z_test)\n",
    "    print(z_test.shape)\n",
    "    print(type(z_test))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(18,5))\n",
    "    plt.subplot(1,3,1)\n",
    "#py.figure(figsize = (14,7))\n",
    "    my_contourf(x,t,z_test.T,r'Source Distrubution')\n",
    "    plt.tight_layout()\n",
    "    plt.subplot(1,3,2)\n",
    "    s_test_nx_nt = s_test.reshape(Nx,Nt)\n",
    "#py.figure(figsize = (14,7))\n",
    "    my_contourf(x,t,s_test_nx_nt,r'Reference Solution')\n",
    "    plt.tight_layout()\n",
    "    plt.subplot(1,3,3)\n",
    "    s_pred_nx_nt = s_pred.reshape(Nx,Nt)\n",
    "#py.figure(figsize = (14,7))\n",
    "    my_contourf(x,t,s_pred_nx_nt,r'Predicted Solution')\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"seventh_2_sample_alpha5.jpg\", dpi=300)\n",
    "    plt.savefig(\"temperature_sample{}_jet12.jpg\".format(i+1), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
